{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUsX4bXP8LeG"
   },
   "outputs": [],
   "source": [
    "# После выполнения этой ячейки нужно перезапустить среду выполнения\n",
    "\n",
    "!pip uninstall scikit-learn\n",
    "!pip install scikit-learn==0.23.2\n",
    "!git clone https://github.com/facebookresearch/fastText.git\n",
    "!cd fastText\n",
    "!sudo pip install fastText\n",
    "!pip install compress-fasttext[full]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZtU_i1vSXmM"
   },
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsyJYitV1Ys2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('prepared_data.csv') #загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5NFkr1xZ-Tz"
   },
   "outputs": [],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "dIQjhYba2IAJ",
    "outputId": "a068b85c-17cb-4efa-90db-22bc051805d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#стоп-слова\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "for w in ['не', 'для', 'при', 'как', 'от', 'на', 'из', 'за', 'yt', 'fc', '.']:\n",
    "    stop.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEtuDAqY2Lie"
   },
   "outputs": [],
   "source": [
    "#словарь аббревиатур из датасета\n",
    "\n",
    "abbr_dict = {'сигма': 'сеть компьютер',\n",
    "             'фпсу': 'фильтр пакет сетевой уровень',\n",
    "             'оптикэш': 'оптимизация заявка перемещение денежный средства внутренний структурный подразделение',\n",
    "             'opticash': 'оптимизация заявка перемещение денежный средства внутренний структурный подразделение',\n",
    "             'вко': 'владелец карточка организация',\n",
    "             'альфа': 'сеть',\n",
    "             'ппрб': 'платформа поддержка развитие бизнес',\n",
    "             'alpha': 'сеть',\n",
    "             'всп': 'внутренний структурный подразделение',\n",
    "             'citrix': 'виртуальный автоматический рабочий место',\n",
    "             'туз': 'технический учетный запись',\n",
    "             'цитрикс': 'виртуальный автоматический рабочий место',\n",
    "             'екс': 'единый корпоративный система',\n",
    "             'вкс': 'владелец карточка сделка',\n",
    "             'впн': 'сеть', 'vpn': 'сеть',\n",
    "             'арм': 'автоматизированный рабочий место',\n",
    "             'варм': 'виртуальный автоматизированный рабочий место',\n",
    "             'егрн': 'единый государственный реестр недвижимость',\n",
    "             'ас': 'автоматизированный система',\n",
    "             'сбо': 'дистанционный доступ счет',\n",
    "             'ериб': 'единый розничный интернет банк',\n",
    "             'нпф': 'негосударственный пенсионный фонд',\n",
    "             'тсв': 'телевизионный система видеоконтроль',\n",
    "             'оптинет': 'заявка перемещение денежный средства внутренний структурный подразделение',\n",
    "             'optinet': 'заявка перемещение денежный средства внутренний структурный подразделение',\n",
    "             'фир': 'файловый информационный ресурс',\n",
    "             'ксш': 'корпоративный сервисный шина'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYaCQAen2V5k"
   },
   "outputs": [],
   "source": [
    "def filter(sent, stop=stop, abbr_dict=abbr_dict):\n",
    "    sent = str(sent).split()\n",
    "    filtered = []\n",
    "    for s in sent:\n",
    "        if abbr_dict.get(s):\n",
    "            for word in abbr_dict.get(s).split():\n",
    "                filtered.append(word)\n",
    "        elif s not in stop:\n",
    "            filtered.append(s)\n",
    "    filtered = ' '.join([s for s in filtered])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sR4sYbu2mC0"
   },
   "outputs": [],
   "source": [
    "data['eng_norm'] = data['eng_norm'].apply(filter)\n",
    "data.drop_duplicates(subset='eng_norm', inplace=True)\n",
    "data['eng_norm'].replace('', np.nan, inplace=True)\n",
    "data.dropna(subset=['eng_norm'], inplace=True)\n",
    "scenarios = data['chosen_scenario']\n",
    "sents = data['eng_norm'].to_list()\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yxaYAPN5cvo"
   },
   "source": [
    "# Создание эмбеддингов запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8HiYsko5hvh"
   },
   "outputs": [],
   "source": [
    "# используем сжатую Fasttext модель, обученную на Национальном Корпусе Русского Языка\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import compress_fasttext\n",
    "small_model = compress_fasttext.models.CompressedFastTextKeyedVectors.load(\n",
    "    'https://github.com/avidale/compress-fasttext/releases/download/v0.0.1/ft_freqprune_100K_20K_pq_100.bin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3YTTyuOVq5X"
   },
   "outputs": [],
   "source": [
    "# Словарь частоты употребления каждого слова\n",
    "def frequency(sents=sents):\n",
    "    word_dict = {}\n",
    "    for sent in sents:\n",
    "        for word in sent.split():\n",
    "            if word_dict.get(word):\n",
    "                word_dict.update({word: word_dict.get(word) + 1})\n",
    "            else:\n",
    "                word_dict.update({word: 1})\n",
    "    return word_dict\n",
    "\n",
    "word_dict = frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xGbjj695lH3"
   },
   "outputs": [],
   "source": [
    "# Из каждого запроса делается один вектор.\n",
    "# Если слово одно, то просто преобразуем его в вектор, если их несколько, то используем most_similar метод\n",
    "embeddings = []\n",
    "for sent in sents:\n",
    "    if len(sent) > 1:\n",
    "        embeddings.append([small_model.most_similar(positive=sent)[0][0],])\n",
    "    else:\n",
    "        embeddings.append(sent)\n",
    "\n",
    "# Загоняем векторные представления всех запросов в массив\n",
    "vectors = np.zeros((len(embeddings),len(small_model[embeddings[0][0]])))\n",
    "i = 0\n",
    "for word in embeddings:\n",
    "    vectors[i] = small_model[word]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "QsOdchvrq_XM",
    "outputId": "0fe27446-c64b-4b44-adb1-9c4456ea1c8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('королева', 0.6860082745552063),\n",
       " ('королевич', 0.6404726505279541),\n",
       " ('королевство', 0.6111368536949158),\n",
       " ('герцог', 0.5870347023010254),\n",
       " ('герцогиня', 0.5689640045166016),\n",
       " ('принцесса', 0.5578069090843201),\n",
       " ('принц', 0.5537070631980896),\n",
       " ('елисавета', 0.5434831380844116),\n",
       " ('королев', 0.5221450328826904),\n",
       " ('царица', 0.5178899168968201)]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример использования метода most_similar\n",
    "\n",
    "small_model.most_similar(positive=['король', 'женщина'], negative=['мужчина'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzFA2hZN5t44"
   },
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uFJg1ITb7WvY",
    "outputId": "8a88ce4c-da7a-4bc2-b917-8aef2110ad63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# Кластеризация при помощи DBSCAN алгоритма\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from scipy.special import comb, logsumexp\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MrC5jHp7aEz"
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.5, min_samples=300, algorithm='ball_tree').fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tAR2Lb0hTx_"
   },
   "outputs": [],
   "source": [
    "db2 = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "w5pi3IBd7cjw",
    "outputId": "4ec4480d-23da-404c-a9f0-50d95814f2fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UrOUdeZhZ41Z",
    "outputId": "21cd095d-1db3-43af-b31f-e1c1db269ea4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, ..., 13, -1, 18])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYOgnnALjDOY"
   },
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zUB0ErgjCae"
   },
   "outputs": [],
   "source": [
    "# Кластеризация при помощи алгоритма K-means\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn import metrics \n",
    "from scipy.spatial.distance import cdist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vM0xap7sjQXg"
   },
   "outputs": [],
   "source": [
    "# Elbow method, с помощью которого можно выбрать оптимальное кол-во кластеров.\n",
    "# Просто смотрим, когда точность модели по заданной метрике уменьшается уже не так сильно, и выбираем граничную точку\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(5,30), metric='calinski_harabaz')\n",
    "visualizer.fit(vectors)        # Fit the data to the visualizer\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzs3QBrmjVQU"
   },
   "outputs": [],
   "source": [
    "# Oбучение на полученном через elbow method значении\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr4RgHNV7i9e"
   },
   "source": [
    "# Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5KRwdex7l7P"
   },
   "outputs": [],
   "source": [
    "# Оценить результат можно на части размеченных данных\n",
    "\n",
    "scenario = scenarios.drop_duplicates()\n",
    "scenario = scenario.to_list()\n",
    "scenario.remove('can_not_answer')\n",
    "scenarios = scenarios.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "B9UK3ZCEvPNW",
    "outputId": "77199250-9e68-4d2f-87fe-ccb6799c77a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzM5E08VsykF"
   },
   "outputs": [],
   "source": [
    "labeled_data = data.copy()\n",
    "labeled_data['label'] = pd.Series(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJrWv8hM5-33"
   },
   "outputs": [],
   "source": [
    "labeled_data.to_excel(\"labeled_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eomzv9Mv5Kbw"
   },
   "outputs": [],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zg95OJtO7uxr"
   },
   "outputs": [],
   "source": [
    "def metric(labels, scenarios=scenarios, scenario=scenario):\n",
    "    true = 0\n",
    "    false = 0\n",
    "    for scen_ex in scenario:\n",
    "        scen_labels = {}\n",
    "        k = 0\n",
    "        for scen, label in zip(scenarios, labels):\n",
    "            if scen_ex == scen:\n",
    "                k += 1\n",
    "                if scen_labels.get(label):\n",
    "                    scen_labels.update({label: scen_labels.get(label) + 1})\n",
    "                else:\n",
    "                    scen_labels.update({label: 1})\n",
    "        if k:\n",
    "            all_values = scen_labels.values()\n",
    "            true += max(all_values)\n",
    "            false += k - max(all_values)\n",
    "    print(\"true: \" + str(true))\n",
    "    print(\"false: \" + str(false))\n",
    "    return(true / (true + false))\n",
    "\n",
    "def word_counter(labels, sents=sents):\n",
    "    labels_dict = {}\n",
    "    for label, sent in zip(labels, sents):\n",
    "        if not labels_dict.get(label):\n",
    "            labels_dict.update({label: {}})\n",
    "        for word in sent.split():\n",
    "            if labels_dict.get(label).get(word):\n",
    "                labels_dict.get(label).update({word: labels_dict.get(label).get(word) + 1})\n",
    "            else:\n",
    "                labels_dict.get(label).update({word: 1})\n",
    "    return(labels_dict)\n",
    "\n",
    "def get_n_most_frequent(dictionary, n=10):\n",
    "    dict_n = {}\n",
    "    i = 0\n",
    "    for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True):\n",
    "        dict_n.update({k: v})\n",
    "        if i < n:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    return dict_n\n",
    "\n",
    "def apply_to_all(dictionary, f):\n",
    "    labels_dict_n = {}\n",
    "    for k, v in dictionary.items():\n",
    "        labels_dict_n.update({k: f(v)})\n",
    "    return labels_dict_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "gjByQXdQ7w8M",
    "outputId": "71a837a9-272a-407e-ed6d-fb991318e075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 8913\n",
      "false: 2881\n"
     ]
    }
   ],
   "source": [
    "m = metric(db.labels_)\n",
    "labels_dict = word_counter(db.labels_)\n",
    "labels_dict_n = apply_to_all(labels_dict, get_n_most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-Hq7T3H98GuQ",
    "outputId": "b990c28f-50a5-4707-eef1-9d6216ac7518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557232491097168"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp0WLYCcPLZ3"
   },
   "outputs": [],
   "source": [
    "def print_n_random_requests(data, n=10):\n",
    "    labels = data['label'].drop_duplicates().tolist()\n",
    "    for label in labels:\n",
    "        ld = data[data['label']==label]\n",
    "        print(label)\n",
    "        print(str(ld.sample(n)['normalized_text']))\n",
    "\n",
    "print_n_random_requests(labeled_data, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJqkenQy6cwC"
   },
   "outputs": [],
   "source": [
    "vector_df = pd.DataFrame(vectors)\n",
    "vector_df.to_csv('vectors.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
